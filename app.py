import os
from dotenv import load_dotenv
import streamlit as st
from datasets import load_dataset
from haystack.document_stores import ChromaDocumentStore
from haystack.nodes import EmbeddingRetriever, PromptNode
from haystack.pipelines import GenerativeQAPipeline
from sentence_transformers import SentenceTransformer

# 1ï¸âƒ£ .env yÃ¼kle
load_dotenv()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
HF_TOKEN = os.getenv("HF_TOKEN")

# 2ï¸âƒ£ Streamlit arayÃ¼z baÅŸlÄ±ÄŸÄ±
st.title("ğŸ“š Kitap YorumlarÄ± Chatbotu")
st.markdown("""
Bu chatbot, Kitapyurdu yorum verisi Ã¼zerinde Ã§alÄ±ÅŸÄ±r ve sorularÄ±nÄ±zÄ± yorumlardan bulup Gemini API ile cevap Ã¼retir.
""")

# 3ï¸âƒ£ Veri seti yÃ¼kleme (HF token ile)
@st.cache_data
def load_kitapyurdu_data():
    dataset = load_dataset(
        "alibayram/kitapyurdu_yorumlar",
        split="train",
        use_auth_token=HF_TOKEN  # HF token burada kullanÄ±lÄ±yor
    )
    documents = []
    for item in dataset:
        documents.append({
            "content": item["review_text"],
            "meta": {"product": item.get("product_title", "")}
        })
    return documents

documents = load_kitapyurdu_data()

# 4ï¸âƒ£ ChromaDB DocumentStore kur
doc_store = ChromaDocumentStore(
    persist_directory="./chroma_db",
    embedding_dim=384
)

# EÄŸer DB boÅŸsa dokÃ¼man ekle
if len(doc_store.get_all_documents()) == 0:
    doc_store.write_documents(documents)

# 5ï¸âƒ£ Retriever kur (embedding modeli)
embedding_model = SentenceTransformer("all-MiniLM-L6-v2")
retriever = EmbeddingRetriever(
    document_store=doc_store,
    embedding_model=embedding_model,
    use_gpu=False
)

# 6ï¸âƒ£ Generator / LLM Node (Gemini)
generator = PromptNode(
    model_name_or_path="google/gemini-2.0",
    api_key=GEMINI_API_KEY,
    default_prompt_template="""
You are an expert assistant answering questions about books based on user reviews.
Use retrieved context to answer precisely and concisely.

Context:
{documents}

Question:
{query}
"""
)

# 7ï¸âƒ£ RAG Pipeline
pipe = GenerativeQAPipeline(generator=generator, retriever=retriever)

# 8ï¸âƒ£ KullanÄ±cÄ± input
user_input = st.text_input("Sorunuzu yazÄ±n:")

if user_input:
    result = pipe.run(query=user_input, params={"Retriever": {"top_k": 3}})
    answer = result["answers"][0].answer
    st.subheader("Cevap:")
    st.write(answer)
